{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "mlflowserver: https://dagshub.com/yeyintaung.ya276/FaceRecognization/experiments"
      ],
      "metadata": {
        "id": "oJN3zs40JcgK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTUK5cZrJwh1",
        "outputId": "f606c730-78c5-4bb7-a96e-7d6daec4bd62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FaceRecognization'...\n",
            "remote: Enumerating objects: 6659, done.\u001b[K\n",
            "remote: Counting objects: 100% (445/445), done.\u001b[K\n",
            "remote: Compressing objects: 100% (231/231), done.\u001b[K\n",
            "remote: Total 6659 (delta 193), reused 437 (delta 185), pack-reused 6214\u001b[K\n",
            "Receiving objects: 100% (6659/6659), 371.99 MiB | 24.69 MiB/s, done.\n",
            "Resolving deltas: 100% (349/349), done.\n",
            "Updating files: 100% (403/403), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/yeaung276/FaceRecognization.git\n",
        "!pip install mlflow\n",
        "%cd FaceRecognization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import mlflow\n",
        "import time\n",
        "import os"
      ],
      "metadata": {
        "id": "iDgj7RZ5JyUo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['MLFLOW_TRACKING_USERNAME'] = 'yeyintaung.ya276'\n",
        "os.environ['MLFLOW_TRACKING_PASSWORD'] = '32874b32af827497261af34e60fe79bbbe838adf'\n",
        "mlflow.set_tracking_uri('https://dagshub.com/yeyintaung.ya276/FaceRecognization.mlflow')\n",
        "def get_experiment_id(name):\n",
        "  exp = mlflow.get_experiment_by_name(name)\n",
        "  if exp is None:\n",
        "    exp_id = mlflow.create_experiment(name)\n",
        "    return exp_id\n",
        "  return exp.experiment_id"
      ],
      "metadata": {
        "id": "qJvfW5dXBR6_"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_description = {\n",
        "    'anchor': tf.io.FixedLenFeature([1024], tf.float32),\n",
        "    'positive': tf.io.FixedLenFeature([1024], tf.float32),\n",
        "    'negative': tf.io.FixedLenFeature([1024], tf.float32),\n",
        "}\n",
        "def parse_example(example_proto):\n",
        "  result = tf.io.parse_single_example(example_proto, feature_description)\n",
        "  return (result['positive'], result['anchor'], result['negative'])"
      ],
      "metadata": {
        "id": "vShJ5oTHMFM8"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = tf.data.TFRecordDataset(\n",
        "    './experiments/data/train-embeddings.gz',\n",
        "    compression_type='GZIP').map(parse_example)\n",
        "eval_data = tf.data.TFRecordDataset(\n",
        "    './experiments/data/eval-embeddings.gz',\n",
        "    compression_type='GZIP').map(parse_example)"
      ],
      "metadata": {
        "id": "38F-hH36JUqY"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DistanceLayer(tf.keras.layers.Layer):\n",
        "    # A layer to compute ‖f(A) - f(P)‖² and ‖f(A) - f(N)‖²\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def call(self, positive, anchor, negative):\n",
        "      ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n",
        "      an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n",
        "      return ap_distance , an_distance"
      ],
      "metadata": {
        "id": "x47tGoAPS0cu"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TripletLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, alpha, name=\"triplet_loss\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.margin = alpha\n",
        "\n",
        "    def call(self, ap_distance, an_distance):\n",
        "        loss = tf.reduce_mean(tf.maximum(ap_distance - an_distance + self.margin, 0.0))\n",
        "        return loss\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'margin': self.margin\n",
        "        }\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, **config}\n",
        "\n",
        "def calc_accuracy(ap_d, an_d):\n",
        "  count = ap_d.shape[0]\n",
        "  return tf.reduce_sum(tf.cast(ap_d < an_d, dtype=tf.int16))/count"
      ],
      "metadata": {
        "id": "KUT5xw6bV9vi"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(\n",
        "    intermediate_layer=32,\n",
        "    output_layer=16,\n",
        "    dropout_strength=0.4\n",
        "):\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(intermediate_layer,\n",
        "              activation='relu'),\n",
        "    tf.keras.layers.Dropout(dropout_strength),\n",
        "    tf.keras.layers.Dense(output_layer,\n",
        "              activation=\"relu\")\n",
        "  ])\n",
        "\n",
        "  # Input Layers for the encoding\n",
        "  anchor_input   = tf.keras.layers.Input(1024, name=\"anchor\")\n",
        "  positive_input = tf.keras.layers.Input(1024, name=\"positive\")\n",
        "  negative_input = tf.keras.layers.Input(1024, name=\"negative\")\n",
        "\n",
        "  ## Generate the encodings (feature vectors) for the images\n",
        "  encoded_a = model(anchor_input)\n",
        "  encoded_p = model(positive_input)\n",
        "  encoded_n = model(negative_input)\n",
        "\n",
        "  ## Calculate distance between anchor and positive/negative\n",
        "  distances = DistanceLayer()(encoded_p, encoded_a, encoded_n)\n",
        "\n",
        "  # Creating the Model\n",
        "  siamese_model = tf.keras.models.Model(\n",
        "          inputs  = [positive_input, anchor_input, negative_input],\n",
        "          outputs = distances,\n",
        "          name = \"Siamese_Network\"\n",
        "      )\n",
        "  return siamese_model, model"
      ],
      "metadata": {
        "id": "3W8a2lnLKO4A"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter\n",
        "EXPERIMENT_NAME='checking_dataset'\n",
        "INTERMEDIATE_LAYER=32\n",
        "OUTPUT_LAYER=16\n",
        "DROPOUT_STRENGTH=0.4\n",
        "NO_EPOCH = 50\n",
        "BATCH_SIZE = 128\n",
        "lr = 1e-3\n",
        "alpha=1.0"
      ],
      "metadata": {
        "id": "LArnYMohKZpd"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_id = get_experiment_id(EXPERIMENT_NAME)\n",
        "print(experiment_id)\n",
        "\n",
        "with mlflow.start_run(experiment_id=experiment_id):\n",
        "  siamese_model, model = create_model(\n",
        "      intermediate_layer=INTERMEDIATE_LAYER,\n",
        "      output_layer=OUTPUT_LAYER,\n",
        "      dropout_strength=DROPOUT_STRENGTH\n",
        "  )\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=lr, epsilon=1e-01)\n",
        "  loss_eval = TripletLoss(alpha=alpha)\n",
        "  mlflow.log_params({\n",
        "     'intermediate_layer': INTERMEDIATE_LAYER,\n",
        "     'output_layer': OUTPUT_LAYER,\n",
        "     'dropout_strength': DROPOUT_STRENGTH,\n",
        "     'epochs': NO_EPOCH,\n",
        "     'batch_size': BATCH_SIZE,\n",
        "     'learning_rate': lr,\n",
        "     'margin_alpha': alpha\n",
        "  })\n",
        "\n",
        "  template = 'ETA: {} - epoch: {} loss: {:.5f} \\\n",
        "  acc: {:.3f}  val loss: {:.5f} val_acc: {:.3f}\\n'\n",
        "\n",
        "  train_loss_metric = tf.keras.metrics.Mean(name=\"loss\")\n",
        "  train_acc_metric = tf.keras.metrics.Mean(name=\"acc\")\n",
        "  train_an_distance = tf.keras.metrics.Mean(name=\"an_d\")\n",
        "  train_ap_distance = tf.keras.metrics.Mean(name=\"ap_d\")\n",
        "\n",
        "  test_loss_metric = tf.keras.metrics.Mean(name=\"loss\")\n",
        "  test_acc_metric = tf.keras.metrics.Mean(name=\"acc\")\n",
        "  test_an_distance = tf.keras.metrics.Mean(name=\"an_d\")\n",
        "  test_ap_distance = tf.keras.metrics.Mean(name=\"ap_d\")\n",
        "\n",
        "  metrics = []\n",
        "\n",
        "  # start training loop\n",
        "  for ep in range(1,NO_EPOCH+1):\n",
        "    t = time.time()\n",
        "    # training batch\n",
        "    for n,a,p in training_data.batch(BATCH_SIZE):\n",
        "      with tf.GradientTape() as tape:\n",
        "        ap_d, an_d = siamese_model([n,a,p])\n",
        "        train_loss = loss_eval(ap_d, an_d)\n",
        "      grads = tape.gradient(train_loss, siamese_model.trainable_weights)\n",
        "      optimizer.apply_gradients(\n",
        "          zip(grads, siamese_model.trainable_weights)\n",
        "      )\n",
        "      train_loss_metric.update_state(train_loss)\n",
        "      train_ap_distance.update_state(ap_d)\n",
        "      train_an_distance.update_state(an_d)\n",
        "      train_acc_metric.update_state(\n",
        "          calc_accuracy(ap_d,an_d)\n",
        "      )\n",
        "    # testing batch\n",
        "    for n,a,p in eval_data.batch(BATCH_SIZE):\n",
        "      ap_d, an_d = siamese_model([n,a,p])\n",
        "      test_loss = loss_eval(ap_d, an_d)\n",
        "      test_loss_metric.update_state(test_loss)\n",
        "      test_ap_distance.update_state(ap_d)\n",
        "      test_an_distance.update_state(an_d)\n",
        "      test_acc_metric.update_state(\n",
        "          calc_accuracy(ap_d, an_d)\n",
        "      )\n",
        "\n",
        "    print(template.format(\n",
        "        round(time.time() - t),\n",
        "        ep,\n",
        "        float(train_loss_metric.result()),\n",
        "        float(train_acc_metric.result()),\n",
        "        float(test_loss_metric.result()),\n",
        "        float(test_acc_metric.result())\n",
        "    ))\n",
        "    metrics.append({\n",
        "        \"train_loss\": train_loss_metric.result(),\n",
        "        \"test_loss\": test_loss_metric.result(),\n",
        "        \"train_acc\": train_acc_metric.result(),\n",
        "        \"test_acc\": test_acc_metric.result(),\n",
        "        \"train_ap\": train_ap_distance.result(),\n",
        "        \"test_ap\": test_ap_distance.result(),\n",
        "        \"train_an\": train_an_distance.result(),\n",
        "        \"test_an\": test_an_distance.result()\n",
        "    })\n",
        "    mlflow.log_metrics({\n",
        "        \"train_loss\": train_loss_metric.result(),\n",
        "        \"test_loss\": test_loss_metric.result(),\n",
        "        \"train_acc\": train_acc_metric.result(),\n",
        "        \"test_acc\": test_acc_metric.result(),\n",
        "        \"train_ap\": train_ap_distance.result(),\n",
        "        \"test_ap\": test_ap_distance.result(),\n",
        "        \"train_an\": train_an_distance.result(),\n",
        "        \"test_an\": test_an_distance.result()\n",
        "    }, step=ep)\n",
        "    # clearing the metric values\n",
        "    train_loss_metric.reset_states()\n",
        "    train_acc_metric.reset_states()\n",
        "    train_ap_distance.reset_states()\n",
        "    train_an_distance.reset_states()\n",
        "    test_loss_metric.reset_states()\n",
        "    test_acc_metric.reset_states()\n",
        "    test_ap_distance.reset_states()\n",
        "    test_an_distance.reset_states()\n",
        "  model.save('./model')\n",
        "  mlflow.log_artifact('./model')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuC4D692Ki4E",
        "outputId": "09eb618b-1d2f-4733-891e-83695baf188a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "ETA: 6 - epoch: 1 loss: 1.38405   acc: 0.519  val loss: 0.99934 val_acc: 0.520\n",
            "\n",
            "ETA: 4 - epoch: 2 loss: 0.98391   acc: 0.534  val loss: 0.97446 val_acc: 0.541\n",
            "\n",
            "ETA: 6 - epoch: 3 loss: 0.95797   acc: 0.550  val loss: 0.95742 val_acc: 0.544\n",
            "\n",
            "ETA: 6 - epoch: 4 loss: 0.92957   acc: 0.562  val loss: 0.95389 val_acc: 0.546\n",
            "\n",
            "ETA: 6 - epoch: 5 loss: 0.90061   acc: 0.584  val loss: 0.92787 val_acc: 0.561\n",
            "\n",
            "ETA: 6 - epoch: 6 loss: 0.87094   acc: 0.599  val loss: 0.91715 val_acc: 0.575\n",
            "\n",
            "ETA: 4 - epoch: 7 loss: 0.84791   acc: 0.613  val loss: 0.90350 val_acc: 0.577\n",
            "\n",
            "ETA: 4 - epoch: 8 loss: 0.82644   acc: 0.622  val loss: 0.89817 val_acc: 0.587\n",
            "\n",
            "ETA: 4 - epoch: 9 loss: 0.80793   acc: 0.632  val loss: 0.89098 val_acc: 0.589\n",
            "\n",
            "ETA: 6 - epoch: 10 loss: 0.79152   acc: 0.641  val loss: 0.89597 val_acc: 0.588\n",
            "\n",
            "ETA: 11 - epoch: 11 loss: 0.78151   acc: 0.646  val loss: 0.88346 val_acc: 0.597\n",
            "\n",
            "ETA: 6 - epoch: 12 loss: 0.76463   acc: 0.660  val loss: 0.89180 val_acc: 0.593\n",
            "\n",
            "ETA: 5 - epoch: 13 loss: 0.75274   acc: 0.664  val loss: 0.87905 val_acc: 0.599\n",
            "\n",
            "ETA: 4 - epoch: 14 loss: 0.74090   acc: 0.671  val loss: 0.88678 val_acc: 0.598\n",
            "\n",
            "ETA: 6 - epoch: 15 loss: 0.73197   acc: 0.676  val loss: 0.88830 val_acc: 0.597\n",
            "\n",
            "ETA: 4 - epoch: 16 loss: 0.72386   acc: 0.681  val loss: 0.89024 val_acc: 0.598\n",
            "\n",
            "ETA: 6 - epoch: 17 loss: 0.71007   acc: 0.685  val loss: 0.88563 val_acc: 0.607\n",
            "\n",
            "ETA: 4 - epoch: 18 loss: 0.69707   acc: 0.695  val loss: 0.88363 val_acc: 0.605\n",
            "\n",
            "ETA: 8 - epoch: 19 loss: 0.68602   acc: 0.698  val loss: 0.88478 val_acc: 0.605\n",
            "\n",
            "ETA: 6 - epoch: 20 loss: 0.67588   acc: 0.704  val loss: 0.88923 val_acc: 0.605\n",
            "\n",
            "ETA: 12 - epoch: 21 loss: 0.67209   acc: 0.709  val loss: 0.88989 val_acc: 0.601\n",
            "\n",
            "ETA: 10 - epoch: 22 loss: 0.65740   acc: 0.713  val loss: 0.88620 val_acc: 0.609\n",
            "\n",
            "ETA: 6 - epoch: 23 loss: 0.64783   acc: 0.717  val loss: 0.88631 val_acc: 0.608\n",
            "\n",
            "ETA: 6 - epoch: 24 loss: 0.64081   acc: 0.721  val loss: 0.88667 val_acc: 0.608\n",
            "\n",
            "ETA: 4 - epoch: 25 loss: 0.63663   acc: 0.722  val loss: 0.88248 val_acc: 0.609\n",
            "\n",
            "ETA: 4 - epoch: 26 loss: 0.62697   acc: 0.726  val loss: 0.88737 val_acc: 0.610\n",
            "\n",
            "ETA: 11 - epoch: 27 loss: 0.62448   acc: 0.729  val loss: 0.88906 val_acc: 0.608\n",
            "\n",
            "ETA: 6 - epoch: 28 loss: 0.61498   acc: 0.736  val loss: 0.89362 val_acc: 0.615\n",
            "\n",
            "ETA: 4 - epoch: 29 loss: 0.61000   acc: 0.741  val loss: 0.89366 val_acc: 0.602\n",
            "\n",
            "ETA: 5 - epoch: 30 loss: 0.59717   acc: 0.745  val loss: 0.90190 val_acc: 0.608\n",
            "\n",
            "ETA: 5 - epoch: 31 loss: 0.59161   acc: 0.747  val loss: 0.92605 val_acc: 0.603\n",
            "\n",
            "ETA: 6 - epoch: 32 loss: 0.59018   acc: 0.750  val loss: 0.93107 val_acc: 0.605\n",
            "\n",
            "ETA: 6 - epoch: 33 loss: 0.58493   acc: 0.754  val loss: 0.93408 val_acc: 0.607\n",
            "\n",
            "ETA: 5 - epoch: 34 loss: 0.57883   acc: 0.758  val loss: 0.91648 val_acc: 0.605\n",
            "\n",
            "ETA: 6 - epoch: 35 loss: 0.56223   acc: 0.766  val loss: 0.92734 val_acc: 0.608\n",
            "\n",
            "ETA: 5 - epoch: 36 loss: 0.54731   acc: 0.773  val loss: 0.94066 val_acc: 0.604\n",
            "\n",
            "ETA: 5 - epoch: 37 loss: 0.54034   acc: 0.775  val loss: 0.94793 val_acc: 0.604\n",
            "\n",
            "ETA: 6 - epoch: 38 loss: 0.53768   acc: 0.779  val loss: 0.94489 val_acc: 0.603\n",
            "\n",
            "ETA: 6 - epoch: 39 loss: 0.53975   acc: 0.780  val loss: 0.96709 val_acc: 0.586\n",
            "\n",
            "ETA: 4 - epoch: 40 loss: 0.54192   acc: 0.777  val loss: 0.96483 val_acc: 0.586\n",
            "\n",
            "ETA: 6 - epoch: 41 loss: 0.53979   acc: 0.781  val loss: 0.96627 val_acc: 0.591\n",
            "\n",
            "ETA: 6 - epoch: 42 loss: 0.54337   acc: 0.776  val loss: 0.97445 val_acc: 0.593\n",
            "\n",
            "ETA: 6 - epoch: 43 loss: 0.54502   acc: 0.777  val loss: 0.96430 val_acc: 0.605\n",
            "\n",
            "ETA: 6 - epoch: 44 loss: 0.55492   acc: 0.775  val loss: 0.95388 val_acc: 0.595\n",
            "\n",
            "ETA: 6 - epoch: 45 loss: 0.55822   acc: 0.773  val loss: 0.94940 val_acc: 0.603\n",
            "\n",
            "ETA: 4 - epoch: 46 loss: 0.57171   acc: 0.765  val loss: 0.94885 val_acc: 0.593\n",
            "\n",
            "ETA: 6 - epoch: 47 loss: 0.55021   acc: 0.774  val loss: 0.96959 val_acc: 0.592\n",
            "\n",
            "ETA: 6 - epoch: 48 loss: 0.51979   acc: 0.788  val loss: 0.97396 val_acc: 0.591\n",
            "\n",
            "ETA: 6 - epoch: 49 loss: 0.50121   acc: 0.795  val loss: 0.98391 val_acc: 0.589\n",
            "\n",
            "ETA: 6 - epoch: 50 loss: 0.50740   acc: 0.793  val loss: 0.97961 val_acc: 0.601\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A_IaK4FRYuKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F0NybnTEZCwo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}